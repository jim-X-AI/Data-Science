{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbbed16c-cb0b-4de5-9c4b-a2a45e8948fd",
   "metadata": {},
   "source": [
    "# END TO END MACHINE LEARNING PROJECT EXAMPLE\n",
    "\n",
    "## Most of the time there are 8 steps you'll usually go through in ML\n",
    "## 1. Look at the big Picture\n",
    "## 2. Get the Data\n",
    "## 3. Discover and Visusalise the data to get insights\n",
    "## 4. Prepare the data for machine learning algorithm\n",
    "## 5. Select a Model and train it\n",
    "## 6. Fine Tune Your model\n",
    "## 7. Present Your solution\n",
    "## 8. Launch Monitor and maintain your system|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515f343-26ae-454d-8997-db42cce77759",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38de21-0258-4230-a579-c1632c670bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e62d593-96cc-41b4-ad06-94b403b7e1c1",
   "metadata": {},
   "source": [
    "## Popular open data repositories\n",
    "UC Irvine Machine Learning Repository\n",
    "\n",
    "Kaggle datasets\n",
    "\n",
    "Amazon’s AWS datasets\n",
    "\n",
    "## Meta portals (they list open data repositories)\r",
    " Data Portal\n",
    "\n",
    "\n",
    " OpenDataMonit\n",
    "    \r\n",
    " ndl\n",
    "\n",
    "##  Other pages listing many popular open data repositories\r",
    "Wikipedia’s list of Machine Learning datasets\n",
    "\n",
    "\n",
    "Quora.co\n",
    "\n",
    "\n",
    "The datasets subreditdditndl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dfdf4c-2a71-41fd-8438-502a05088ed4",
   "metadata": {},
   "source": [
    "# Before You begin any data science project you need to understand what the objective is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3aea2b-b6ce-4a7c-bc88-ccab12f504e9",
   "metadata": {},
   "source": [
    "# 2. Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5fa46-b0eb-4853-b005-1eb48802738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For file manipulation \n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "# For .tar files\n",
    "import tarfile\n",
    "# For getting infomation from the web through http(dowmload files)\n",
    "import urllib.request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f61a9-28bb-4cff-9f29-6b587807f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def housing_data():\n",
    "    # This takes into account the file path end\n",
    "    path = Path('datasets/housing.tgz')\n",
    "\n",
    "    # The condition if it isnt a file\n",
    "    if not path.is_file():\n",
    "        # This checks if its the parent and if it exist\n",
    "        Path('datasets').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        url = 'https://github.com/ageron/data/raw/main/housing.tgz'\n",
    "        urllib.request.urlretrive(url, path)\n",
    "\n",
    "        with tarfile.open(path) as housing_tar:\n",
    "            housing_tar.extractall(path='datasets')\n",
    "\n",
    "    return pd.read_csv(Path('datasets/housing/housing.csv'))\n",
    "\n",
    "housing_d = housing_data()\n",
    "\"\"\"\n",
    "The function checks if the file datasets/housing.tgz exists.\n",
    "If the file doesn't exist, it downloads it from the provided URL.\n",
    "It then extracts the contents of the .tgz file into the datasets/housing/ directory.\n",
    "After extraction, the function reads the CSV file (housing.csv) into a pandas DataFrame and returns it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db8025d-b540-4980-941d-35f42b93413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820c39b-a8da-4427-8f87-9dea1ecfd5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_d.info()\n",
    "\"\"\"\n",
    "The \n",
    "info()\n",
    "method is useful to get a quick description of the data, in\n",
    "particular the total number of rows, each attribute’s type, and the number of\n",
    "nonnull values \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517dce7-558f-47c8-bf73-0828b73f3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_d['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dcf01a-0fb2-4d9a-96b2-b68b888113e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_d.describe() # For numerical description of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0ab02-b0c4-4012-a651-9d7c9b416477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the images as high res images on the notebook\n",
    "IMAGE_PATH = Path() / 'images' / 'end_to_end project'\n",
    "IMAGE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension='png', resolution=300):\n",
    "    path = IMAGE_PATH / f'{fig_id}.{fig_extension}'\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1292e57f-6be9-4187-a396-69d135bfad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Not necessary just for specification\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "# Very necessary\n",
    "housing_d.hist(figsize=(20, 15), bins=50)\n",
    "save_fig('Histogram of housing california')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629e1ff-a4a2-41bd-b663-01a702f300f1",
   "metadata": {},
   "source": [
    "# Its important to understand how the data was computed for isntance, the housing median income was scaled at \n",
    "# Many histograms are tail heavy as they extend much father to the right of the median  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb073b-6c06-417b-9a14-d40dd37b0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a test set of the data you can use sklearn.model selection import train_test_split if you are familiar with it\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def train_test(data, test_ratio):\n",
    "     shuffled_indicies = np.random.permutation(len(data))\n",
    "     test_set_size = int(len(data) * test_ratio)\n",
    "     test_indicies = shuffled_indicies[:test_set_size]\n",
    "     train_indicies = shuffled_indicies[test_set_size:]\n",
    "     return data.iloc[train_indicies],  data.iloc[test_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170bf241-773c-4f04-b612-8554065b3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test(housing_d, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f800ff8-a110-4ee1-b292-ed8a6733e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'No of rows of the train_set: {len(train)}')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c83a8-4d9f-4262-844c-46c7401f5cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'No of rows of the test_set: {len(test)}')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d94a2f2-95c2-4b72-aac0-00bfd076713d",
   "metadata": {},
   "source": [
    "## You do not want your machine learning algorithm to view the entire data set cuz evrytime you run the fxn you get a different set of data so we will be trying a new algorithm\n",
    "we need to call np.random.permutation() before calling np.random.seed() is the solution.\n",
    "Sadly, this won't guarantee that this notebook will output exactly the same results as in the notebook, since there are other possible sources of variation. The most important is the fact that algorithms get tweaked over time when libraries evolve. So please tolerate some minor differences: hopefully, most of the outputs should be the same, or at least in the right ballpark.\n",
    "\n",
    "Note: another source of randomness is the order of Python sets: it is based on Python's `hash()` function, which is randomly \"salted\" when Python starts up (this started in Python 3.3, to prevent some denial-of-service attacks). To remove this randomness, the solution is to set the `PYTHONHASHSEED` environment variable to `\"0\"` _before_ Python even starts up. Nothing will happen if you do it after that. Luckily, if you're running this notebook on Colab, the variable is already set for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be5e4c-fab4-490f-870f-c55e6ef98326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zlib import crc32\n",
    "def is_id_in_test_set(identifier, test_ratio):\n",
    "    return crc32(np.int64(identifier)) < test_ratio * 2 ** 32\n",
    "\n",
    "\n",
    "def split_data_with_id_hash(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: is_id_in_test_set(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2092e-70ad-4128-a27d-afecc8753cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_with_id = housing_d.reset_index() # adds a new column called index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5803b2d-9fe7-4dba-95cc-6ad081649b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_with_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e252fc8-d97e-4782-9bf4-e2879a3e16d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = split_data_with_id_hash(id_column='index', data=housing_with_id, test_ratio=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bee4d6-ef2a-4612-ad13-e10bd6eedd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26207ae4-ca37-441e-8926-715ff2b09859",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3b91e-3fba-42b8-abcd-98b1eebcf085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing_with_id['id'] = housing_d['longitude'] * 1000 + housing_d['latitude']\n",
    "train_set, test_set = split_data_with_id_hash(id_column='id', data=housing_with_id, test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7edbaba-bb34-43cc-a40f-59cc9e2b56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_test, test_set = train_test_split(housing_d, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ce1f1-7ce8-4693-ae31-b63e77c187bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['total_bedrooms'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c9cd0-dcdf-4ef9-aacf-966eca9809d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['total_bedrooms'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb396c1-7a42-4256-be0f-ac25b902e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf2823a-cb97-4de1-82cd-ac0b215a2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_d.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaddaa5-c54b-45da-bb56-6282d4af3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f284913-fe98-498a-bc53-884f7a335292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – shows how to compute the 10.7% proba of getting a bad sample\n",
    "\n",
    "from scipy.stats import binom\n",
    "\n",
    "sample_size = 1000\n",
    "ratio_female = 0.511\n",
    "proba_too_small = binom(sample_size, ratio_female).cdf(485 - 1)\n",
    "proba_too_large = 1 - binom(sample_size, ratio_female).cdf(535)\n",
    "print(proba_too_small + proba_too_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ed92e-7276-4916-af88-47a74ee939ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_d['Income Category'] = pd.cut(housing_d['median_income'], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651ecb20-9968-4f02-8fc3-46b63b14d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_d['Income Category'].value_counts().sort_index().plot.bar(rot=0, grid=True)\n",
    "plt.xlabel(\"Income category\")\n",
    "plt.ylabel(\"Number of districts\")\n",
    "save_fig(\"housing_income_cat_bar_plot\")  # extra code\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd294a2-8e7b-4258-baa4-368b47103e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "stratified_split = []\n",
    "for train_index, test_index in split.split(housing_d, housing_d['Income Category']):\n",
    "    train_set = housing_d.iloc[train_index]\n",
    "    test_set = housing_d.iloc[test_index]\n",
    "    stratified_split.append([train_set, test_set])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08a4bd-fe81-498b-8137-73597d3fd785",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set, strat_test_set = stratified_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac97ec9-e785-4280-a01c-d416c4163914",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set['Income Category'].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00f2df9-289a-40de-852a-81cada5d816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set['Income Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca24c97-ebb8-4ade-9d96-e61f5457b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop('Income Category', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd7812-583a-4e55-9dd3-7eff442bcdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4075af80-8b0b-49f5-88e6-b1dcca06240d",
   "metadata": {},
   "source": [
    "# 3. Discover and Visualise the data to gain insight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d0b95-3450-44f1-8344-7aacaa5714e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720265b-2fda-4a20-95f9-2950ce6f8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind='scatter',  x='longitude', y='latitude')\n",
    "save_fig('Bad visualisation plot')\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", grid=True, alpha=0.2)\n",
    "save_fig('Good visualisation plot')\n",
    "housing.plot(kind='scatter', x='longitude', y='latitude',\n",
    "             grid=True, s=housing['population'] / 100, label='population',\n",
    "            c='median_house_value', cmap='jet', colorbar=True, legend=True,\n",
    "            sharex=False, figsize=[10, 7])\n",
    "save_fig('scatter plot of housing prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58f463-2e56-4d4a-88ec-839560c54993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO download california housing\n",
    "file_name = 'california.png'\n",
    "if not (IMAGE_PATH/file_name).is_file():\n",
    "    github_root = 'https://github.com/ageron/handson-ml3/raw/main/'\n",
    "    url = github_root + 'images/starters notebook' + file_name\n",
    "    print(f'Downloading: {file_name}')\n",
    "    urllib.request.urlretrieve(IMAGE_PATH/file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc205760-b604-4fae-987d-6efa12914686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
